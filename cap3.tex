\section{Atribuição de valor a imagens de refeições}

\subsection{Arquitetura do sistema}

Para o trabalho utilizamos um desktop com 32GB de RAM i7-4790K CPU @ 4.00GHz com placa de vídeo GeForce GTX 980.

\subsubsection{TensorFlow}

O aprendizado de máquina é uma disciplina complexa. Porém, hoje, a implementação de modelos de aprendizado de máquina é mais simples do que costumava ser, graças aos frameworks de aprendizado de máquina, como o TensorFlow, que facilitam o processo de aquisição de dados, modelos de treinamento, previsões e refinamento de resultados futuros.

%https://www.infoworld.com/article/3278008/tensorflow/what-is-tensorflow-the-machine-learning-library-explained.html

%https://aws.amazon.com/pt/tensorflow/

O TensorFlow é uma biblioteca de software de código aberto para computação numérica que usa gráficos de fluxo de dados. Os nós no gráfico representam operações matemáticas, e as arestas representam as matrizes ou tensores de dados multidimensionais que se comunicam com os nós. Essa arquitetura flexível permite a implantação de aplicações a uma ou mais CPUs ou GPUs em um desktop, servidor ou dispositivo móvel sem reescrever o código. O TensorFlow também inclui o TensorBoard, um kit de ferramentas de visualização de dados. O TensorBoard é um conjunto web de aplicativos para inspecionar e entender suas execuções e gráficos do TensorFlow.

O TensorFlow foi desenvolvido originalmente por pesquisadores e engenheiros que trabalham na equipe do Google Brain, na organização Machine Intelligence Research do Google, com o objetivo de realizar pesquisas sobre redes neurais profundas e aprendizado de máquina. Ele fornece tudo para o programador por meio da linguagem Python. O Python é fácil de aprender e trabalhar. Nós e tensores em TensorFlow são objetos Python, e os aplicativos TensorFlow são aplicativos em Python.

As operações matemáticas reais, entretanto, não são executadas no Python. As bibliotecas de transformações que estão disponíveis através do TensorFlow são escritas como binários C ++ de alto desempenho. O Python apenas direciona o tráfego entre as partes e fornece abstrações de programação de alto nível para conectá-las.

O maior benefício que o TensorFlow oferece para o desenvolvimento de aprendizado de máquina é a abstração. Em vez de lidar com os detalhes básicos da implementação de algoritmos, ou de descobrir formas adequadas de ligar a saída de uma função à entrada de outra, o desenvolvedor pode se concentrar na lógica geral da aplicação. TensorFlow cuida dos detalhes nos bastidores.


\subsubsection{Keras}
Keras é uma API de redes neurais de alto nível, escrita em Python e capaz de rodar em cima do TensorFlow, CNTK ou Theano que pode rodar na CPU ou GPU.

Princípios orientadores

Facilidade de utilização: Keras é uma API projetada para seres humanos, não para máquinas. Coloca a experiência do usuário na frente e no centro. I Keras segue as práticas recomendadas para reduzir a carga cognitiva: ele oferece APIs consistentes e simples, minimiza o número de ações do usuário necessárias para casos de uso comuns e fornece um feedback claro e acionável sobre o erro do usuário.

Modularidade: Um modelo é entendido como uma sequência ou um gráfico de módulos autônomos configuráveis que podem ser conectados com o menor número de restrições possível. Em particular, camadas neurais, funções de custo, otimizadores, esquemas de inicialização, funções de ativação, esquemas de regularização são todos módulos independentes que você pode combinar para criar novos modelos.

Extensibilidade fácil: Novos módulos são simples de adicionar (como novas classes e funções), e os módulos existentes fornecem exemplos amplos. Poder criar facilmente novos módulos permite total expressividade, tornando Keras adequado para pesquisa avançada.

Trabalhe com o Python: Não há arquivos de configuração de modelos separados em um formato declarativo. Os modelos são descritos em código Python, que é compacto, mais fácil de depurar e permite a facilidade de extensibilidade.

Aplicações Keras são modelos de deep learning que são disponibilizados juntamente com pesos pré-treinados. Esses modelos podem ser usados para previsão, extração de recursos e ajuste fino.

%https://keras.io/#keras-the-python-deep-learning-library

\subsection{Modelos de redes neurais considerados e sua avaliação}


Os modelos disponíveis para classificação de imagens com pesos treinados no ImageNet são:

\begin{itemize}
    \item Xception
    \item VGG16
    \item VGG19
    \item ResNet50
    \item InceptionV3
    \item InceptionResNetV2
    \item MobileNet
    \item DenseNet
    \item NASNet
    \item MobileNetV2
\end{itemize}

Todas essas arquiteturas são compatíveis com todos os backends (TensorFlow, Theano e CNTK).

Os modelos utilizados nesse trabalho foram o MobileNetV2, DenseNet121 e o NASNetMobile.

\subsubsection{MobileNetV2}
Em 2017, um grupo de pesquisadores do Google publicou um artigo que apresentava uma arquitetura de rede neural otimizada para dispositivos móveis. Essa arquitetura chamada de MobileNets são modelos pequenos, com baixa latência e baixo consumo de energia parametrizados para atender às restrições de recursos de vários casos de uso. Eles podem ser construídos para classificação, detecção, incorporação e segmentação, semelhante a como outros modelos populares de grande escala, como o Inception, são usados. Os MobileNets podem ser executados de forma eficiente em dispositivos móveis com o TensorFlow Mobile.

%https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html

%https://towardsdatascience.com/mobilenetv2-inverted-residuals-and-linear-bottlenecks-8a4362f4ffd5

A capacidade de executar redes profundas em dispositivos móveis pessoais melhora a experiência do usuário, oferecendo acesso a qualquer hora, em qualquer lugar, com benefícios adicionais para segurança, privacidade e consumo de energia. À medida que novos aplicativos surgem, permitindo que os usuários interajam com o mundo real em tempo real, o mesmo acontece com a necessidade de redes neurais cada vez mais eficientes. Por isso, a Google apresentou uma nova versão dessa arquitetura esse ano, o MobileNetV2.


O MobileNetV2 é uma melhoria significativa em relação ao MobileNetV1 e impulsiona o estado da arte para reconhecimento visual móvel, incluindo classificação, detecção de objetos e segmentação semântica. O MobileNetV2 baseia-se nas ideias do MobileNetV1, porém, a V2 introduz dois novos recursos à arquitetura: Resíduos Invertidos e Gargalos Lineares.

Em comparação com a primeira versão, no geral, os modelos do MobileNetV2 são mais rápidos com a mesma precisão em todo o espectro de latência. Em particular, os novos modelos usam duas vezes menos operações, precisam de 30\% menos parâmetros e são cerca de 30-40\% mais rápidos em um telefone do Google Pixel do que os modelos do MobileNetV1, tudo isso com maior precisão.

%https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html

\begin{figure}[!ht]
\centering 
\caption{O MobileNetV2 melhora a velocidade (latência reduzida) e aumenta a precisão do ImageNet Top 1}
\label{fig:mobilenetv1vsv2}
\includegraphics[width=0.9\textwidth]{imgs/mobilenetv1vsv2.png}
\end{figure}


\subsubsection{DenseNet121}

À medida que as CNNs se tornam cada vez mais profundas, surge um novo problema de pesquisa: conforme as informações sobre a entrada ou gradiente passam por várias camadas, elas podem desaparecer antes de chegar ao fim da rede.

%https://arxiv.org/pdf/1608.06993.pdf

Redes Convolucionais Densamente Conectadas (DenseNets) simplificam o padrão de conectividade entre camadas introduzidas em outras arquiteturas. Os autores resolvem o problema garantindo o fluxo máximo de informações (e gradientes). Para fazer isso, eles simplesmente conectam cada camada diretamente entre si. Em vez de extrair poder de representação de arquiteturas extremamente profundas ou amplas, as DenseNets exploram o potencial da rede por meio do reuso de recursos. As DenseNets requerem menos parâmetros que um CNN tradicional equivalente, já que não há necessidade de aprender mapas de recursos redundantes.

DenseNets, em contraste com ResNets, nunca combinam recursos por meio do somatório antes de serem passados para uma camada. Em vez disso, combinam recursos concatenando-os.
Assim, a camada l tem l entradas, consistindo nos mapas de características de todos os blocos convolucionais precedentes. Seus próprios mapas de características são passados para todas as camadas subsequentes de L-l. Isso introduz as conexões L (L + 1) 2 em uma rede de camada L, em vez de apenas L, como nas arquiteturas tradicionais. Devido ao seu denso padrão de conectividade, a abordagem foi chamada de Dense Convolutional Network (DenseNet).

\begin{figure}[!ht]
\centering 
\caption{Um bloco denso de 5 camadas com uma taxa de crescimento de k = 4. Cada camada usa todos os mapas de recursos anteriores como entrada.}
\label{fig:densenet}
\includegraphics[width=0.9\textwidth]{imgs/densenets.jpg}
\end{figure}

\subsubsection{NASNetMobile}

%https://towardsdatascience.com/everything-you-need-to-know-about-automl-and-neural-architecture-search-8db1863682bf